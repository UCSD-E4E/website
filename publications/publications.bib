@INPROCEEDINGS{santos_barnes_lo_et_al_ieee_mass_2014,
	title={Small Unmanned Aerial Vehicle System for Wildlife Radio Collar Tracking}, 
	DOI={10.1109/mass.2014.48}, 
	booktitle={2014 IEEE 11th International Conference on Mobile Ad Hoc and Sensor Systems}, 
	author={Santos, Gilberto Antonio Marcon Dos and Barnes, Zachary and Lo, Eric and Ritoper, Bryan and Nishizaki, Lauren and Tejeda, Xavier and Ke, Alex and Lin, Han and Schurgers, Curt and Lin, Albert and Kastner, Ryan}, 
	year={2014}, 
	volume={},
	number={},
	pages={761-766},
	url = {https://ieeexplore.ieee.org/document/7035779},
	keywords={signal to noise ratio, global positioning system, finite element analysis, wildlife, hardware, receivers, aircraft, autonomous aerial vehicles, directional antennas, radio tracking, signal processing, small unmanned aerial vehicle system, wildlife radio collar tracking, VHF signal, custom signal processing algorithms, small fixed-wing aircraft drone, wildlife telemetry, software-defined radio, digital signal processing},
	abstract={This paper describes a low cost system for tracking wildlife that is equipped with radio collars. Currently, researchers have to physically go into the field with a directional antenna to try to pinpoint the VHF (very high frequency) signal originating from a wildlife tracking collar. Depending on the terrain, it could take an entire day to locate a single animal. To vastly improve upon this traditional approach, the system proposed here utilizes a small fixed-wing aircraft drone with a simple radio on-board, flying an automated mission. Received signal strength is recorded, and used to create a heat map that shows the collar's position. A prototype of this system was built using off-the-shelf hardware and custom signal processing algorithms. Initial field tests confirm the systems capabilities and its promise for wildlife tracking.}}
@INPROCEEDINGS{webber_hui_kastner_et_al_ieee_icnc_2017,
    title={Radio receiver design for Unmanned Aerial wildlife tracking}, 
    DOI={10.1109/iccnc.2017.7876260}, 
    booktitle={2017 International Conference on Computing, Networking and Communications (ICNC)}, 
    author={Webber, Daniel and Hui, Nathan and Kastner, Ryan and Schurgers, Curt}, 
    year={2017}, 
    pages={942-946}, 
    url={https://ieeexplore.ieee.org/document/7876260},
    keywords = {radio receiver design, unmanned aerial wildlife tracking, radio collars, wildlife biologists, behavior patterns, low cost unmanned aerial system, sensitive receiver chain, transponders},
    abstract={The use of radio collars is a common method wildlife biologists use to study behavior patterns in animals. Tracking a radio collar from the ground is time consuming and arduous. This task becomes more difficult as the size and output power decreases to accommodate animals as small as an iguana. Our solution is to fly a low cost Unmanned Aerial System equipped with a sensitive receiver chain to locate several transponders at once. The challenge is that the system needs to be low cost and be able to detect the transponder within a range of tens of feet. Initial ground tests indicate that the system was able to detect a collar 70 feet away for under \$100.}}
@misc{hui_ucsd_2019,
	abstract = {Radio telemetry is a critical technique in conservation ecology, particularly for studying the movement and range of individuals and populations. Traditionally, most radio telemetry work is done using handheld directional antennae by using either direction-finding and homing techniques, or radio-triangulation techniques. Over the past couple decades, efforts have been made to utilize aerial vehicles to make radio telemetry tracking more efficient, or cover more area. However, many these approaches require the use of manned aircraft and specialist skill sets. The proliferation of small unmanned aerial systems (SUAS) with high reliability and ease of use, as well as recent development and application of robotic sensing and estimation, opens up the possibility of leveraging SUAS to conduct radio telemetry studies. In this thesis, I present the results of five years of development as well as the testing and deployment of a drone-based radio-telemetry tracking system that is able to track multiple targets simultaneously while operating in field conditions as part of a field expedition.}, 
	author = {Hui, Nathan}, 
	address = {La Jolla, Calif}, 
	booktitle = {Efficient Drone-based Radio Tracking of Wildlife}, 
	keywords = {Drone, Radio Tracking, SUAS, Wildlife Telemetry}, 
	language = {eng}, 
	publisher = {University of California, San Diego}, 
	title = {Efficient Drone-based Radio Tracking of Wildlife }, 
	year = {2019},
	url={https://escholarship.org/uc/item/4574s85j}}
@article{hui_lo_moss_et_al_jfr_2021,
	author = {Hui, Nathan T. and Lo, Eric K. and Moss, Jen B. and Gerber, Glenn P. and Welch, Mark E. and Kastner, Ryan and Schurgers, Curt}, 
	title = {A more precise way to localize animals using drones}, 
	journal = {Journal of Field Robotics}, 
	year = {2021},
	keywords = {aerial robotics, environmental monitoring, exploration, rotorcraft}, 
	doi = {https://doi.org/10.1002/rob.22017}, 
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22017}, 
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.22017}, 
	abstract = {Abstract Radio telemetry is a commonly used technique in conservation biology and ecology, particularly for studying the movement and range of individuals and populations. Traditionally, most radio telemetry work is done using handheld directional antennae and either direction-finding and homing techniques or radio-triangulation techniques. Over the past couple of decades, efforts have been made to utilize unmanned aerial vehicles to make radio-telemetry tracking more efficient, or cover more area. However, many of these approaches are complex and have not been rigorously field-tested. To provide scientists with reliable quality tracking data, tracking systems need to be rigorously tested and characterized. In this paper, we present a novel, drone-based, radio-telemetry tracking method for tracking the broad-scale movement paths of animals over multiple days and its implementation and deployment under field conditions. During a 2-week field period in the Cayman Islands, we demonstrated this system's ability to localize multiple targets simultaneously, in daily 10 min tracking sessions over a period of 2 weeks, generating more precise estimates than comparable efforts using manual triangulation techniques.}}
@INPROCEEDINGS{wilby_kastner_hostler_et_al_oceans_2016,  
	author={Wilby, Antonella and Kastner, Ryan and Hostler, Andrew and Slattery, Ethan},  
	booktitle={OCEANS 2016 MTS/IEEE Monterey},   
	title={Design of a low-cost and extensible acoustically-triggered camera system for marine population monitoring},   
	year={2016},  
	volume={},  
	number={},  
	pages={1-9},  
	doi={10.1109/OCEANS.2016.7761320},
	abstract={As the health of the ocean continues to decline, more and more marine populations are at risk of extinction. A significant challenge facing conservation biologists is the ability to effectively monitor at-risk populations due to the challenges of the underwater environment. Obtaining visual data on a marine species typically requires significant time spent by humans observing in the field, which is both costly and time-consuming, and often yields a small amount of data. We present a low-cost, acoustically-triggered camera system to enable remote monitoring and identification of marine populations.}}
@inproceedings{wilby_slattery_hostler_et_al_wuwnet_2016,
	author = {Wilby, Antonella and Slattery, Ethan and Hostler, Andrew and Kastner, Ryan},
	title = {Autonomous Acoustic Trigger for Distributed Underwater Visual Monitoring Systems},
	year = {2016},
	isbn = {9781450346375},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2999504.3001080},
	doi = {10.1145/2999504.3001080},
	abstract = {The ability to obtain reliable, long-term visual data in marine habitats has the potential
	to transform biological surveys of marine species. However, the underwater environment
	poses several challenges to visual monitoring: turbidity and light attenuation impede
	the range of optical sensors, biofouling clouds lenses and underwater housings, and
	marine species typically range over a large area, far outside of the range of a single
	camera sensor. Due to these factors, a continuously-recording or time-lapse visual
	sensor will not be gathering useful data the majority of the time, wasting battery
	life and filling limited onboard storage with useless images. These limitations make
	visual monitoring difficult in marine environments, but visual data is invaluable
	to biologists studying the behaviors and interactions of a species. This paper describes
	an acoustic-based, autonomous triggering approach to counter the current limitations
	of underwater visual sensing, and motivates the need for a distributed sensor network
	for underwater visual monitoring.},
	booktitle = {Proceedings of the 11th ACM International Conference on Underwater Networks &amp; Systems},
	articleno = {10},
	numpages = {5},
	keywords = {autonomous monitoring, underwater cameras, acoustic triggering, biological surveys},
	location = {Shanghai, China},
	series = {WUWNet '16}
	}
@article{tolkova_bauer_wilby_et_al_jasa_2017,
	author = {Tolkova,Irina  and Bauer,Lisa  and Wilby,Antonella  and Kastner,Ryan  and Seger,Kerri },
	title = {Automatic classification of humpback whale social calls},
	journal = {The Journal of the Acoustical Society of America},
	volume = {141},
	number = {5},
	pages = {3605-3605},
	year = {2017},
	doi = {10.1121/1.4987715},
	URL = {https://doi.org/10.1121/1.4987715},
	eprint = {https://doi.org/10.1121/1.4987715},
	abstract={Acoustic methods are an established technique to monitor marine mammal populations and behavior, but developments in computer science can expand the current capabilities. A central aim of these methods is the automated detection and classification of marine mammal vocalizations. While many studies have applied bioacoustic methods to cetacean calls, there has been limited success with humpback whale (Megaptera novaeangliae) social call classification, which has largely remained a manual task in the bioacoustics community. In this project, we automated this process by analyzing spectrograms of calls using PCA-based and connected-component-based methods, and derived features from relative power in the frequency bins of these spectrograms. These features were used to train and test a supervised Hidden Markov Model (HMM) algorithm to investigate classification feasibility. We varied the number of features used in this analysis by varying the sizes of frequency bins. Generally, we saw an increase in precision, recall, and accuracy for all three classified groups, across the individual data sets, as the number of features decreased. We will present the classification rates of our algorithm across multiple model parameters. Since this method is not specific to humpback whale vocalizations, we hope it will prove useful in other acoustic applications.}}
@INPROCEEDINGS{beluso_xu_patamasing_et_al_massw_2019,  
	author={Beluso, Charmaine and Xu, Anfeng and Patamasing, Eamon and Sebastian, Brian and Lo, Eric and Schurgers, Curt and Kastner, Ryan and Chen, Liren and Yu, Xuanyi and Sturm, Dan and Barlow, Robert},  
	booktitle={2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems Workshops (MASSW)},   
	title={D-SEA: The Underwater Depth Sensing Device for Standalone Time-Averaged Measurements},   
	year={2019},  
	volume={},  
	number={},  
	pages={101-105},  
	doi={10.1109/MASSW.2019.00027},
	url={https://doi.org/10.1109/MASSW.2019.00027},
	abstract={Access to accurate depth information is important for a wide variety of oceanographic science applications. For example, it is crucial in the creation of 3D models. Currently, divers are manually measuring the depth by using dive watches, but this method is inconsistent because of variable depth readings caused by changing wave heights and human errors. To combat these problems, we created the Depth-Sensor Enclosed Application (D-SEA) to automatically collect and average pressure data while displaying the calculated depth readings underwater. To use D-SEA, the user places it on top of the area of study to measure and gather the underwater depth readings over time. We are working on an affordable, waterproof prototype with a display that is readable underwater, an automatic transition between on and off states when submerged in seawater, and automatic data logging onto an SD card. From testing the recent prototype, results show that D-SEA lasted for weeks in the sleep state and days in the wake state while under depths of 4.40 meters.}}
@inproceedings{hicks_kastner_schurgers_et_all_neurips_2020,
	title={Mangrove Ecosystem Detection using Mixed-Resolution Imagery with a Hybrid-Convolutional Neural Network},
	author={Hicks, Dillon and Kastner, Ryan and Schurgers, Curt and Hsu, Astrid and Aburto, Octavio},
	year={2020},
	volume={},
	number={},
	pages={},
	doi={},
	booktitle={Thirty-fourth Conference on Neural Information Processing Systems},
	url={https://www.climatechange.ai/papers/neurips2020/23/paper.pdf},
	abstract={Mangrove forests are rich in biodiversity and are a large contributor to carbon sequestration critical in the fight against climate change. However, they are currently under threat from anthropogenic activities, so monitoring their health, extent, and productivity is vital to our ability to protect these important ecosystems. Traditionally, lower resolution satellite imagery or high resolution unmanned air vehicle (UAV) imagery has been used independently to monitor mangrove extent, both offering helpful features to predict mangrove extent. To take advantage of both of these data sources, we propose the use of a hybrid neural network, which combines a Convolutional Neural Network (CNN) feature extractor with a Multilayer-Perceptron (MLP), to accurately detect mangrove areas using both medium resolution satellite and high resolution drone imagery. We present a comparison of our novel Hybrid CNN with algorithms previously applied to mangrove image classification on a data set we collected of dwarf mangroves from consumer UAVs in Baja California Sur, Mexico, and show a 95% intersection over union (IOU) score for mangrove image classification, outperforming all our baselines}}
@INPROCEEDINGS{ayers_jandali_hwang_et_al_icml_2021,
	author = {Ayers, Jacob and Jandali, Yaman and Hwang, Yoo Jin and Steinberg, Gabriel and Joun, Erika and Tobler, Mathias and Ingram, Ian and Kastner, Ryan and Schurgers, Curt},
	title = {Challenges in Applying Audio Classification Models to Datasets Containing Crucial Biodiversity Information},
	booktitle = {38th International Conference on Machine Learning},
	year = {2021},
	volume={38},
	abstract={The acoustic signature of a natural soundscape can reveal consequences of climate change on biodiversity. Hardware costs, human labor time, and expertise dedicated to labeling audio are impediments to conducting acoustic surveys across a representative portion of an ecosystem. These barriers are quickly eroding away with the advent of low-cost, easy to use, open source hardware and the expansion of the machine learning field providing pre-trained neural networks to test on retrieved acoustic data. One consistent challenge in passive acoustic monitoring (PAM) is a lack of reliability from neural networks on audio recordings collected in the field that contain crucial biodiversity information that otherwise show promising results from publicly available training and test sets. To demonstrate this challenge, we tested a hybrid recurrent neural network (RNN) and convolutional neural network (CNN) binary classifier trained for bird presence/absence on two Peruvian bird audiosets. The RNN achieved an area under the receiver operating characteristics (AUROC) of 95% on a dataset collected from Xeno-canto and Google’s AudioSet ontology in contrast to 65% across a stratified random sample of field recordings collected from the Madre de Dios region of the Peruvian Amazon. In an attempt to alleviate this discrepancy, we applied various audio data augmentation techniques in the network’s training process which led to an AUROC of 77% across the field recordings}}
% Optional fields: volume, number, pages, month, note
@ARTICLE{gautier_garrison_rushton_jchmsd_2020,
	author = {Gautier, Quentin Kevin and Garrison, Thomas G and Rushton, Ferril and Bouck, Nicholas and Lo, Eric and Tueller, Peter and Schurgers, Curt and Kastner, Ryan},
	title = {Low-cost 3D scanning systems for cultural heritage documentation},
	journal = {Journal of Cultural Heritage Management and Sustainable Development},
	year = {2020},
	issn = {2044-1266},
	volume={10},
	number={4},
	pages={437-455},
	DOI={https://doi.org/10.1108/JCHMSD-03-2020-0032},
	URL={https://www.emerald.com/insight/content/doi/10.1108/JCHMSD-03-2020-0032/full/html},
	abstract={Digital documentation techniques of tunneling excavations at archaeological sites are becoming more common. These methods, such as photogrammetry and LiDAR (Light Detection and Ranging), are able to create precise three-dimensional models of excavations to complement traditional forms of documentation with millimeter to centimeter accuracy. However, these techniques require either expensive pieces of equipment or a long processing time that can be prohibitive during short field seasons in remote areas. This article aims to determine the effectiveness of various low-cost sensors and real-time algorithms to create digital scans of archaeological excavations.},
	keywords={archaeology, cultural heritage, documentation, surveying and recording, mapping}}